Tasks:
- Incorporate a GNN model instead of MLP/KAN
- Adjust encoding/decoding and inferencing methods so they handle graphs (adjacency + node features) rather than feature vectors

- Add a GNN model class
- Create a GNN in surrogate folder
- Reference GNN in self.models

Use PyTorch's Geometric (PyG) which provides implementation of GNN layers, data handling for graphs and training utils.
# Integrating a GNN-Based Surrogate in a NAS Pipeline

Using a **Graph Neural Network (GNN)** as a performance surrogate in Neural Architecture Search (NAS) can capture rich structural information about candidate networks. Below, we outline key considerations and best practices from recent research for integrating a GNN-based surrogate, focusing on: (1) genome embedding, (2) graph representation, (3) GNN model selection, (4) training techniques, and (5) comparisons to MLP or transformer surrogates.

## 1. Genome Embedding Strategies

**Encoding the architecture (“genome”)** effectively is crucial so that the GNN can interpret it. Various strategies exist for representing a candidate architecture in a vector or graph form before feeding it to a model:

- **One-Hot or Sequence Encodings:** Early NAS methods often encode architectures as strings or sequences (e.g. layer types and connections). For example, approaches like PNAS and NAO use string sequences, and BANANAS uses a **path-based encoding** that enumerates all paths from input to output ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=is%20to%20encode%20the%20computation,following%20a%20topological%20ordering%20of)). This path encoding is **permutation-invariant** to graph isomorphism and was shown to scale better than adjacency-matrix encodings for MLP predictors ([BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search](https://cdn.aaai.org/ojs/17233/17233-13-20727-1-2-20210518.pdf#:~:text=%E2%80%A2%20We%20propose%20a%20novel,than%20the%20adjacency%20matrix%20encoding)). However, such fixed encodings may explode in size for complex graphs ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=to%20process%20architecture%20graph%20data,2020%29%20directly%20utilized)).
    
- **Adjacency Matrix + Features:** Another approach is to flatten the architecture’s adjacency matrix (connectivity) along with node operation labels into a fixed-length vector. This “embedding matrix” approach was used in some predictor-based NAS methods (e.g. SemiNAS) ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=utilized%20to%20trans%02form%20the%20discrete,trained%20predictor%2C%20prior)). It requires careful design of the vectorization and typically feeding it into an MLP or transformer. While simple, this can struggle to capture structural nuances unless augmented with domain knowledge.
    
- **Graph-Based Embedding:** Represent the architecture **as a graph directly** and let a GNN learn its embedding. In this approach, each network architecture is a directed acyclic graph (DAG) where **nodes represent operations/layers** and **edges represent connections** ([FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search | OpenReview](https://openreview.net/forum?id=fMX07g3prp#:~:text=an%20architecture%27s%20potential%20without%20exhaustive,We%20subsequently%20assess%20our)). An initial feature (embedding) is assigned to each node indicating its operation type or other attributes. For example, Lukasik _et al._ use a _learnable look-up table_ to embed node types (e.g. conv3x3, maxpool) into initial node feature vectors ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=Let%20be%20a%20graph%20with,passing%20process)). These node features, together with the adjacency structure, serve as the “genome” input for the GNN surrogate. This learned embedding strategy lets the model capture complex relationships without manual encoding of entire architectures.
    
- **Hybrid Strategies:** Some recent works combine ideas. _Arch2vec_ (Yan _et al._, 2020) trains a graph variational autoencoder to embed architectures into a latent vector space ([Graph Embedding for Neural Architecture Search with Input-Output Information](https://2022.automl.cc/wp-content/uploads/2022/07/graph_embedding_for_neural_arc.pdf#:~:text=original%20arch2vec%20VAE%20to%20encode,the%20other%20are%20the%20predicted)). It uses a GNN (Graph Isomorphism Network) encoder to ensure architectures with the same graph structure map to the same embedding ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=the%20DAG%2C%20which%20ensures%20the,Yan%20et%20al)). Such latent embeddings can then be fed to a predictor (e.g. a simple regression head or even a separate model like a random forest) for performance estimation. This two-step approach (unsupervised graph embedding + supervised predictor) can leverage unlabelled architectures to improve representation learning.
    

**Key point:** The encoding should retain as much structural information as possible while being invariant to graph isomorphisms (i.e. relabelling of nodes). GNN-based encodings naturally offer this invariance by treating the architecture as a graph rather than as an ordered sequence ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=is%20to%20encode%20the%20computation,following%20a%20topological%20ordering%20of)), whereas sequence or matrix encodings often need additional handling (e.g. canonical orderings or data augmentation) to avoid treating the same architecture as different due to arbitrary node indexing.

## 2. Graph Representation Techniques for Architectures

When using a GNN surrogate, how you construct the architecture’s graph representation can greatly impact performance. **Effective graph representations maximize useful structural information** and align with how the GNN will perform message-passing. Consider the following best practices:

- **Node and Edge Features:** Define what each node and edge represents. In most NAS search spaces (like NAS-Bench-101 or DARTS), architectures are represented as DAGs of operations ([FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search | OpenReview](https://openreview.net/forum?id=fMX07g3prp#:~:text=an%20architecture%27s%20potential%20without%20exhaustive,We%20subsequently%20assess%20our)). A common approach is to use **nodes for operations** (e.g. convolution, pooling, add, etc.) and directed edges indicating data flow. Each node gets a feature vector encoding its operation type (via one-hot or an embedding vector) ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=Let%20be%20a%20graph%20with,passing%20process)). If the _connections themselves have properties_ (e.g. an edge could represent a specific data transformation), you could also assign labels or features to edges, though many works keep edges untyped and only derive structure from them ([[2004.01899] A Generic Graph-based Neural Architecture Encoding Scheme for Predictor-based NAS](https://arxiv.org/abs/2004.01899#:~:text=Scheme%2C%20a,based%20neural)). GATES (Ning _et al._, 2020) is an encoding scheme that treats **operations as transformations on the messages passed along edges**, consistently handling both “operation on node” and “operation on edge” search spaces ([[2004.01899] A Generic Graph-based Neural Architecture Encoding Scheme for Predictor-based NAS](https://arxiv.org/abs/2004.01899#:~:text=Scheme%2C%20a,based%20neural)).
    
- **Incorporating Graph Structure:** Use the natural DAG structure of the network. GNN message passing will propagate information across connections. It’s important to include special nodes if needed (e.g. an **input node** representing the data input and an **output node** aggregating outputs of the network) so that the graph fully represents how data flows through the architecture ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=propose%20a%20surrogate%20model%20for,101%20dataset)) ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=After%20the%20final%20round%20of,single%20graph%20embedding%20%2C%20where)). Many NAS search spaces already define a single input and output node in the graph encoding of an architecture (as in NAS-Bench-101).
    
- **Directed vs Undirected Handling:** Neural network graphs are directed (from input toward output). Standard GNNs often treat graphs as undirected or simply aggregate neighborhood information. To handle directionality, one technique is **bidirectional message passing** – i.e. include both forward and backward edges in the graph or use separate passes. Lukasik _et al._ add a _reverse message-passing_ process to their GNN so that information flows both downstream and upstream in the DAG ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=,add%20a%20reverse%20message%20module)). Similarly, the recent FR-NAS method explicitly combines the **“conventional” (forward) and “inverse” (reversed)** graph representations to capture effects from both ends of the network ([FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search | OpenReview](https://openreview.net/forum?id=fMX07g3prp#:~:text=neural%20networks%20,space%2C%20with%20a%20training%20data)) ([FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search | OpenReview](https://openreview.net/forum?id=fMX07g3prp#:~:text=based%20predictors,16%5C%25%20in%20terms%20of%20prediction)). Including reverse edges or using two GNN passes (one on the original graph, one on the reversed graph) can improve how well the surrogate understands skip connections or long-range dependencies.
    
- **Graph Connectivity and Aggregation:** Ensure the GNN can effectively aggregate the whole architecture’s information. After a few rounds of message passing, you typically need to produce a **graph-level representation** (since the surrogate outputs a single performance prediction for the whole architecture). Common techniques include _global pooling_ (summing or averaging node embeddings) or more sophisticated aggregators. For instance, one model uses a gated pooling where each node’s contribution to the final graph embedding is weighted by a learned gate ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=After%20the%20final%20round%20of,single%20graph%20embedding%20%2C%20where)). Designing the aggregation to consider important nodes (like output nodes or high-degree nodes) can improve prediction quality. In practice, sum or mean pooling is simple and permutation-invariant ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=multiple%20rounds%20of%20propagation%20and,of%20parameters%20for%20each%20round)), while attention pooling could weight more critical substructures.
    
- **Handling Multiple Cells or Hierarchy:** If the search space is cell-based (e.g. an architecture is composed of multiple repeating cells), you have options: represent the **entire network as one graph** (connecting cells via edges), or **encode each cell as a subgraph** and have the surrogate process them separately or hierarchically. Some implementations treat each cell architecture as a graph and then combine cell-level embeddings (e.g. by another aggregation or simple concatenation) to get the full network’s representation. The strategy should reflect the granularity at which your NAS pipeline views the “genome.” The key is to consistently include all parts of the architecture in the graph input so the surrogate has the complete picture.
    

In summary, use a graph representation that mirrors the neural network’s structure, label the components (nodes/edges) with informative features, and utilize techniques like bidirectional edges or appropriate pooling to ensure no important structural information is lost. These practices help the GNN surrogate learn the mapping from architecture graph to performance more effectively ([[2004.01899] A Generic Graph-based Neural Architecture Encoding Scheme for Predictor-based NAS](https://arxiv.org/abs/2004.01899#:~:text=operations%20as%20the%20transformation%20of,available%20at%20this%20https%20URL)).

## 3. Choosing the GNN Model Class

Several GNN variants could serve as the surrogate model. The choice of GNN affects how information is aggregated from the architecture graph. Common model classes and their considerations include:

- **Graph Convolutional Networks (GCN):** GCNs apply a spectral or message-passing convolution that aggregates a node’s neighbors’ features (often using a simple mean or sum). GCNs are a popular choice and have been used successfully for NAS performance prediction. For example, **BRP-NAS** (Dudziak _et al._, 2020) uses a GCN-based predictor to estimate network latency, with each node’s feature encoding the operator type and the graph connectivity providing structure ([](https://www.microsoft.com/en-us/research/uploads/prod/2021/02/dnnperf.pdf#:~:text=AutoML%20community%20has%20also%20expressed,to%20obtain%20true%20accuracy%20but)). GCNs are relatively simple and efficient; they work well when the graph isn’t too large (NAS cell graphs usually have on the order of tens of nodes). One limitation is that vanilla GCNs treat all neighbors equally (no distinction in importance), but they are a strong baseline and easy to implement.
    
- **Graph Attention Networks (GAT):** GAT introduces attention weights to the message-passing, so a node can weigh messages from different neighbors differently. In a NAS context, a GAT surrogate could learn to pay more attention to certain influential connections (e.g. a skip connection or a particular operation that significantly affects accuracy). If certain parts of the architecture are more critical for performance, the attention mechanism may capture this. Research on NAS surrogates has indeed explored attention mechanisms – e.g. the GATES encoding scheme effectively uses a form of attentive message passing by simulating the computation flow, which can be seen as assigning different importance to different input paths ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=but%20scales%20exponentially%20with%20the,Yan%20et%20al)). GATs can be beneficial but also add more parameters. They haven’t been as widely reported as GCNs in NAS literature, but they are a logical extension when one suspects that **not all nodes or connections contribute equally** to performance.
    
- **GraphSAGE (Inductive GNNs):** GraphSAGE aggregates neighbor information through operations like mean, max-pool, or LSTM aggregator, and can sample neighbors in large graphs. In NAS, GraphSAGE’s strength (handling very large graphs or inductive settings where new nodes appear) might be less critical since typical architecture graphs are moderate-sized and from a fixed search space. However, GraphSAGE or similar message-passing neural networks could still be used as the surrogate model. For example, **PerfGraph** or similar approaches could use a mean aggregator to combine features of a node’s predecessors. If your NAS pipeline might encounter varying graph sizes or you want to train on smaller cell graphs and apply to a larger network graph, an inductive approach like GraphSAGE could generalize well. Empirically, many NAS predictor papers stick to simpler GCN/MLP models ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=utilized%20to%20trans%02form%20the%20discrete,trained%20predictor%2C%20prior)), but GraphSAGE is a viable alternative, especially if you plan to scale to architectures with hundreds of nodes (e.g. entire networks rather than cells).
    
- **Graph Isomorphism Networks (GIN) and MPNNs:** GIN is a powerful GNN variant that is as discriminative as the Weisfeiler-Lehman graph isomorphism test (it uses sum aggregation with learnable weights) – this was used in **arch2vec** to embed architectures, specifically to enforce that isomorphic graphs map to identical embeddings ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=the%20DAG%2C%20which%20ensures%20the,Yan%20et%20al)). GIN or other Message Passing Neural Networks (MPNNs) with sophisticated update functions (like the GRU-based updates in Lukasik _et al._ ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=Exploring%20many%20different%20choices%20for,of%20parameters%20for%20each%20round))) can be chosen to increase expressiveness. For instance, a surrogate could use a **GGNN (Gated Graph Neural Network)** which is essentially an MPNN with gated recurrent unit updates – this lets the model retain some memory of past message-passing iterations and potentially capture long-range effects more effectively ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=Exploring%20many%20different%20choices%20for,of%20parameters%20for%20each%20round)). These models might improve accuracy at the cost of complexity.
    
- **Hybrid or Specialized Models:** Some recent works combine GNNs with other architectures. A _transformer-enhanced GNN_ is one example: Wu _et al._ (2021) propose a predictor mixing GNN with transformer to capture global interactions ([[PDF] A Neural Architecture Predictor based on GNN-Enhanced Transformer](https://proceedings.mlr.press/v238/xiang24a/xiang24a.pdf#:~:text=,NAS)). Another approach, _PINAT (Permutation Invariant Augmented Transformer)_, mainly uses a transformer but draws inspiration from GNNs to enforce permutation invariance ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=we%20propose%20a%20partial%20permutation,obtain%20par%02tial%20and%20global%20permutation)). While not pure GNNs, these highlight that one can incorporate attention or other deep architectures on top of graph representations. If the NAS pipeline’s search space is very large or complex, exploring such hybrid models might yield benefits, though they typically need more training data ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=Besides%2C%20CATE%20%28Yan%20et%20al,method%20enabled%20both%20the%20global)).
    

**Choosing a model class** often involves trade-offs: GCNs (and similar simple MPNNs) are **lightweight and work well with limited data**, whereas more expressive models (GAT, GIN, or transformer-based) **capture complex patterns but may require more parameters or data**. It’s a good practice to start with a simple GCN or GraphSAGE – these have shown solid results in predictor-based NAS (e.g., GCN-based predictors were part of winning NAS methods in several studies ([](https://www.microsoft.com/en-us/research/uploads/prod/2021/02/dnnperf.pdf#:~:text=AutoML%20community%20has%20also%20expressed,to%20obtain%20true%20accuracy%20but))). If that proves insufficient, consider adding attention or using a more powerful GNN variant. Also, ensure the model aligns with the _search space properties_: for instance, if your “genome” has weighted or multi-typed edges, a model that can incorporate edge features (like a relational GNN) would be appropriate.

## 4. Training Best Practices for GNN Surrogates

Training a GNN surrogate in NAS can be challenging due to typically **limited training data** (every data point is an architecture that was fully evaluated, which is expensive). Here are best practices to train and optimize the GNN surrogate effectively:

- **Data Collection & Augmentation:** Gather as much diverse training data as feasible from the search space. This may include randomly sampled architectures and their performance or architectures sampled from past NAS iterations. Because GNNs are data-efficient with structured data, even a few hundred samples can be workable ([FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search | OpenReview](https://openreview.net/forum?id=fMX07g3prp#:~:text=utilization%20of%20both%20types%20of,16%5C%25%20in%20terms%20of%20prediction)), but more is better. Consider _augmentation techniques_ to artificially expand the training set:
    
    - **Permutation invariance augmentation:** Since an architecture graph can be permuted without changing its meaning, you can present the same architecture in different graph index orderings to the GNN during training (effectively augmenting the data). This helps the model learn to ignore node ordering. Some works build this into the model (e.g. by design GNNs are invariant, or via specialized modules ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=Permutation%20invariance%20for%20graphs%20As,The%20former))), but if using any model that isn’t inherently invariant (like a transformer or an MLP on adjacency vectors), this augmentation is crucial.
    - **Semi-supervised signals:** If you have access to untrained architectures, you can use unsupervised objectives (as in arch2vec) to pre-train the GNN on the space of graphs. Another idea is to include **low-fidelity evaluations** – e.g. performance after fewer training epochs – to get additional labels cheaply, and train the GNN to predict those as well. This multi-fidelity training can regularize the model, though care must be taken to distinguish fidelity levels.
    - **Feature augmentation:** Some implementations add extra meta-features to each architecture’s representation (for example, the number of parameters, or a handcrafted feature like “total FLOPs”). Including such features as additional node or graph attributes can improve prediction if those correlate with performance. Ensure any added features are normalized and don’t break the spirit of NAS (e.g., using the true accuracy as a feature would be cheating!).
- **Loss Functions:** Most surrogate models treat performance prediction as a regression problem, using Mean Squared Error (MSE) or Mean Absolute Error (MAE) between predicted and true accuracy (or any performance metric). For instance, PPP-Net (an earlier NAS predictor) predicted accuracy to avoid the cost of full training, but observed a regression error ([](https://www.microsoft.com/en-us/research/uploads/prod/2021/02/dnnperf.pdf#:~:text=models%20,70%5D%20Compared)). MSE is common and directly optimizes for accuracy of the prediction. However, NAS often cares more about **ranking** architectures correctly than absolutely precise accuracy values. Thus, some works convert the task into a _ranking problem_: e.g. **BRP-NAS** formulates it as a binary classification of which of two architectures is better, effectively optimizing a ranking loss ([](https://www.microsoft.com/en-us/research/uploads/prod/2021/02/dnnperf.pdf#:~:text=AutoML%20community%20has%20also%20expressed,to%20obtain%20true%20accuracy%20but)). Similarly, you can use a loss like Kendall tau or a pairwise hinge loss on rankings to prioritize getting the order right. A practical compromise is to use a regression loss but monitor rank-based metrics and possibly include a secondary loss term for ranking. **Auxiliary losses** can also help – FR-NAS introduced a feature-based loss to ensure the GNN learned effectively from both forward and reverse graph views ([FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search | OpenReview](https://openreview.net/forum?id=fMX07g3prp#:~:text=based%20predictors,16%5C%25%20in%20terms%20of%20prediction)). If your GNN surrogate has multiple outputs (for example, predicting accuracy and latency simultaneously), a multi-task loss can be used to train it to predict all targets at once, potentially improving generalization by shared learning.
    
- **Regularization and Preventing Overfit:** Given the small dataset regime, regularization is critical. Use techniques like:
    
    - **Dropout:** Apply dropout to the GNN layers or to the final embedding to avoid overfitting (this was used in an MLP baseline with success, e.g. dropout 0.3 in an MLP surrogate) – similar can be applied to GNN layers.
    - **Weight decay:** L2 regularization on GNN weights helps constrain the model.
    - **Early stopping:** Monitor validation error (e.g. on a held-out set of architecture-performance pairs) and stop training when the error begins to rise. With very few samples, the surrogate can overfit training data quickly.
    - **Ensembling:** An ensemble of predictors can improve robustness. BANANAS, for instance, trains an ensemble of MLP predictors to get uncertainty estimates and better performance ([naszilla/docs/bananas.md at master - GitHub](https://github.com/naszilla/naszilla/blob/master/docs/bananas.md#:~:text=naszilla%2Fdocs%2Fbananas.md%20at%20master%20,the%20validation%20accuracy%20of)). You can similarly train multiple GNNs (with different random initializations or even different architectures) and average their predictions. This reduces variance and gives more reliable guidance to the NAS.
    - **Cross-Validation:** If the dataset of evaluated architectures is extremely small, cross-validation on that set to train the surrogate can squeeze out more reliable estimates. For example, train on 80 architectures and validate on 20, in 5 folds rotated; then either use an ensemble of the 5 models or use the CV performance as an estimate of surrogate quality. This is more for measuring the surrogate’s capability before trusting it in the NAS loop.
- **Optimization and Hyperparameters:** Train the GNN with a suitable optimizer (Adam is common for predictors) and use learning rate scheduling if needed ([surrogate_eval.py](file://file-l8qnb6mexhfza4pexb6z7z%23:~:text=,cosineannealinglr:%20scheduler%20=%20scheduler_func(optimizer=optimizer,%20t_max=10/)). A typical setup might be a modest learning rate (e.g. 1e-3) decayed over time. Because the dataset is small, each epoch is quick – you might train for many epochs (hundreds or more) but with early stopping to avoid overfit. Use batch training if possible (batching multiple architecture graphs) – frameworks like PyTorch Geometric or DGL allow batching of small graphs easily. Batch normalization on node features (if architecture features have different scales) could help, but often the features are categorical (operation types) so this is less an issue than in image data.
    
- **Evaluation of Surrogate:** Track metrics that matter for NAS:
    
    - **Rank correlation** (Spearman’s rho or Kendall’s tau) between predicted and true performance is a key indicator of how well the surrogate can guide search ([[PDF] Dynamic Ensemble of Low-Fidelity Experts: Mitigating NAS “Cold ...](https://ojs.aaai.org/index.php/AAAI/article/view/26339/26111#:~:text=%5BPDF%5D%20Dynamic%20Ensemble%20of%20Low,2021)). A high rank correlation means the surrogate reliably orders architectures similar to ground truth – important for selecting top candidates.
    - **Mean prediction error** (RMSE or MAE) gives absolute accuracy of the predictions.
    - **Success@K** (optional): whether the surrogate’s top-K predicted architectures contain the true top performer. This directly measures if it can pick winners.
    - Use a **hold-out test set** of architectures not seen in training (and ideally from a different distribution, e.g. if doing NAS-Bench-101, hold out some cluster of architectures) to ensure the surrogate generalizes to new designs. Lukasik _et al._ specifically tested **zero-shot prediction**, where the surrogate is evaluated on structurally **unseen architectures**, to demonstrate generalization ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=high%20computational%20costs%2C%20most%20recent,101%20dataset)). You may emulate this by splitting train/test based on some structural attribute (e.g., train on smaller architectures, test on larger ones).
- **Iterative Retraining:** In practice, when the surrogate is integrated in the NAS loop, you will periodically update it with newly evaluated architectures. A best practice is to **retrain or fine-tune the surrogate incrementally** as new data comes in, rather than only once. This can be done by fine-tuning the existing model a few epochs with the new data (and perhaps some old data to avoid forgetting), or by retraining from scratch if the dataset has grown significantly. Keep an eye on predictor drift: as the search explores new regions, the surrogate may become less certain, so maintaining a measure of uncertainty (via an ensemble or dropout-based Bayesian approximation) can signal when to retrain or when predictions are less reliable.
    

In summary, training a GNN surrogate is a balancing act: you want the model to be powerful enough to capture architecture-performance relationships, but simple enough to learn from limited data. Use appropriate losses (possibly including ranking), regularize well, and evaluate in a way that aligns with NAS goals (mostly ranking). Following these practices yields a surrogate that can significantly accelerate the NAS by quickly predicting candidate performance.

## 5. Comparison with MLP and Transformer-Based Surrogates

**How do GNN surrogates stack up against traditional multi-layer perceptrons (MLPs) or newer transformer-based predictors?** Recent research and implementations provide some insights:

- **MLP Surrogates (with manual encodings):** MLP or other simple models were among the first surrogate predictors in NAS. They require the architecture to be encoded as a fixed-length vector (via one-hot, adjacency matrix, path encoding, etc.). When a good encoding is chosen, MLP surrogates can perform surprisingly well. For instance, the BANANAS framework found that a 10-layer feed-forward network using their path-based encoding outperformed graph-based models in their experiments ([BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search](https://cdn.aaai.org/ojs/17233/17233-13-20727-1-2-20210518.pdf#:~:text=the%20adjacency%20matrix%20or%20path,with%2010%20layers%20of%20width)). The path encoding gave the MLP a rich representation of the architecture (covering all input-output paths) and led to high accuracy in predicting validation accuracy ([BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search](https://cdn.aaai.org/ojs/17233/17233-13-20727-1-2-20210518.pdf#:~:text=%E2%80%A2%20We%20propose%20a%20novel,than%20the%20adjacency%20matrix%20encoding)). In general, MLP surrogates are **fast and easy to train**, but their weakness lies in the encoding: it’s challenging to hand-craft a vector representation that captures all relevant aspects of a neural architecture. They may also struggle to extrapolate beyond the patterns seen in training – e.g., an architecture with a novel connection pattern might confuse an MLP that was trained on a fixed-position adjacency vector.
    
- **GNN Surrogates:** GNNs naturally address some shortcomings of MLPs by directly leveraging the graph structure of architectures. They do not require one to decide an ordering of nodes or enumerate paths; instead, the GNN learns a representation through message passing. **Graph-based surrogates tend to be more parameter-efficient** for structured data and **invariant to isomorphisms**, which makes them robust. Research shows that GNN predictors can achieve higher sample efficiency – Ning _et al._ report that their graph-based encoding (GATES) improved predictor accuracy and boosted the sample-efficiency of predictor-based NAS (finding good architectures with fewer evaluations) ([[2004.01899] A Generic Graph-based Neural Architecture Encoding Scheme for Predictor-based NAS](https://arxiv.org/abs/2004.01899#:~:text=modeling%20of%20the%20neural%20architectures%2C,available%20at%20this%20https%20URL)). GNN surrogates are also better at generalizing to larger or different graphs not seen in training. For example, Lukasik _et al._’s GNN was able to predict performance for _unseen_ architecture structures (zero-shot) reasonably well ([[2010.10024] Neural Architecture Performance Prediction Using Graph Neural Networks](https://ar5iv.org/pdf/2010.10024#:~:text=high%20computational%20costs%2C%20most%20recent,101%20dataset)), something that a simple surrogate would struggle with. On the downside, GNNs might be slower per prediction than a small MLP (due to message-passing overhead), but for NAS applications the difference is usually negligible since the graphs are small (and far cheaper than a full training run of the candidate network).
    
- **Transformer-Based Surrogates:** Transformer models (or other sequence models like LSTMs) have also been applied to NAS prediction, treating the architecture description as a sequence of tokens or a set of elements. Transformers can capture complex interactions via self-attention and are very expressive. _CATE_ (Yan _et al._, 2021) and _TNASP_ (Lu _et al._, 2021) use transformer encoders for architecture prediction ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=Besides%2C%20CATE%20%28Yan%20et%20al,method%20enabled%20both%20the%20global)). These models showed improved prediction accuracy, but with caveats: the transformer-based predictor had a lot more parameters and needed more training data to avoid overfitting ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=Besides%2C%20CATE%20%28Yan%20et%20al,method%20enabled%20both%20the%20global)). A naive transformer also doesn’t inherently respect graph structure, so one must encode the architecture as a sequence (which brings back the permutation issue) or modify the transformer. The PINAT approach (AAAI 2023) specifically **injects permutation invariance modules** into a transformer to handle architecture graphs, effectively imitating what GNNs naturally do ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=we%20propose%20a%20partial%20permutation,obtain%20par%02tial%20and%20global%20permutation)). This yielded strong results, outperforming a standard transformer that lacks those invariances ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=Besides%2C%20CATE%20%28Yan%20et%20al,property%2C%20thus%20outper%02forming%20them%20obviously)). In summary, transformers can match or exceed GNN performance if designed well, but they **introduce more complexity** and typically require larger training sets (hundreds or thousands of architectures) to tune their many parameters.
    
- **Other Surrogates:** Aside from MLP/GNN/Transformer, some works have used support vector regressors, random forests, or Gaussian processes on top of learned embeddings (e.g. NAO used an RNN encoder and a GP for prediction). These can work in small-data regimes but generally, learning an embedding with a neural network and using a simple regressor on top is the more modern approach. RNN-based predictors (like an LSTM that reads an architecture description) have also been tried – e.g., _PPP-Net_ used an RNN to avoid full training of each model ([](https://www.microsoft.com/en-us/research/uploads/prod/2021/02/dnnperf.pdf#:~:text=the%20learning%20performance%20%28e,70%5D%20Compared)). RNNs, however, face similar challenges as transformers regarding sequence order and have largely been overtaken by GNN approaches in recent literature.
    
- **Performance Comparison:** Empirically, GNN surrogates often outperform or match MLPs when the encoding for the MLP is not heavily optimized. When encoding is optimized (like BANANAS’ path encoding), MLPs can be strong, but GNNs still offer a more **general solution** that requires less manual feature engineering. For example, in NAS-Bench-101 experiments, a GCN-based predictor (as in BRP-NAS) was very effective but had limited cross-space generalization ([](https://www.microsoft.com/en-us/research/uploads/prod/2021/02/dnnperf.pdf#:~:text=AutoML%20community%20has%20also%20expressed,to%20obtain%20true%20accuracy%20but)); newer GNN models (like FR-NAS’s dual-view GNN) further improve on that, achieving up to 16% better accuracy than prior predictors ([FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search | OpenReview](https://openreview.net/forum?id=fMX07g3prp#:~:text=conventional%20and%20inverse%20graph%20representations%2C,leading%20predictors%20on%20benchmark%20datasets)) ([FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search | OpenReview](https://openreview.net/forum?id=fMX07g3prp#:~:text=based%20predictors,16%5C%25%20in%20terms%20of%20prediction)). This indicates the field is advancing towards more powerful GNN-based surrogates. In contrast, purely MLP or transformer predictors haven’t reported such leaps without significant tuning or data. In practice, many NAS researchers choose GNN-based surrogates for their **balance of efficiency and effectiveness**, unless the search space is very simple (where a trivial encoding suffices) or extremely large (where a transformer might capture higher-order interactions given enough data).
    
- **Use Case Considerations:** If your NAS pipeline is limited in evaluated samples (which is common), a GNN surrogate is a safe bet because it can generalize from fewer examples by leveraging inductive biases about graph structure ([FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search | OpenReview](https://openreview.net/forum?id=fMX07g3prp#:~:text=an%20architecture%27s%20potential%20without%20exhaustive,GNN%20predictor%20to%20ensure%20efficient)). If you have abundant data or want to push for the absolute lowest prediction error, you might experiment with transformer-based models or very deep neural predictors, but be prepared for a longer development and training cycle. Simpler MLP surrogates might be appropriate as a baseline or if integration simplicity is a priority (since they take a flat vector input, they can plug into existing code easily). However, keep in mind that an MLP’s performance hinges on the quality of the architecture encoding you design ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=utilized%20to%20trans%02form%20the%20discrete,trained%20predictor%2C%20prior)). By using a GNN, you let the model learn the encoding function for you through its message passing mechanism.
    

**In summary**, GNN surrogates provide a powerful middle ground: they naturally encode the _inductive bias_ that neural networks are graphs, which leads to better sample efficiency and generalization in NAS tasks. They have proven competitive or superior to hand-engineered MLP encodings in many cases ([[2004.01899] A Generic Graph-based Neural Architecture Encoding Scheme for Predictor-based NAS](https://arxiv.org/abs/2004.01899#:~:text=modeling%20of%20the%20neural%20architectures%2C,available%20at%20this%20https%20URL)), and they are less cumbersome than transformer models that require handling graph permutations explicitly. Best practices from recent research strongly favor graph-based representations for NAS performance prediction due to their ability to capture architectural nuances and generalize across the search space ([](https://www.microsoft.com/en-us/research/uploads/prod/2021/02/dnnperf.pdf#:~:text=AutoML%20community%20has%20also%20expressed,to%20obtain%20true%20accuracy%20but)) ([PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor](https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848#:~:text=but%20scales%20exponentially%20with%20the,Yan%20et%20al)).

Combining these insights – by carefully encoding architectures as graphs, choosing an appropriate GNN variant, training with rigorous techniques, and understanding the alternatives – will help integrate a GNN-based surrogate into your NAS pipeline effectively. This integration can dramatically speed up the search by guiding it toward promising regions of the architecture space with learned knowledge, rather than blind exploration, all while maintaining confidence that the surrogate is leveraging the true structure of the neural architectures it evaluates.


# Graph Representation of Architectures
___
- **Conversion Function:** Write a helper function to convert each individual’s genome (or architecture description) into a graph representation.
- **Nodes and Edges:** In your graph, nodes represent operations or layers (e.g., convolution, pooling) and edges represent the data flow between these operations.
- **Node Features:** Each node might have features such as layer type, number of filters, kernel size, activation functions, etc.

**Training the GNN:**
- **Dataset:** Use your evaluated architectures as training data. Each data point will consist of a graph (the individual architecture) and its corresponding performance metric.
- **Loss Function:** Train your GNN using a regression loss (e.g., Mean Squared Error) to predict the performance metric.