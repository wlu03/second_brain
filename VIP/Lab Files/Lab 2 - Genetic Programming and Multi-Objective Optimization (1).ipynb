{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Genetic Programming and Multi-Objective Optimization\n",
    "### Written by Austin Dunn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Run all the code cells below in order to ensure everything runs correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we are going to focus on a different kind of evolutionary algorithm than genetic algorithms. This lab will be focused on genetic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genetic programming is an evolutionary approach to generating computer programs. GP is the tool we will use for automated algorithm design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by importing the libraries we need for GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create our fitness and individual classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time our individual class inherits from DEAP's PrimitiveTree class instead of a list. This is because our individuals will be represented as a tree structure. Trees are the most common data structure used in GP. In GP, trees are made of functions and variables called primitives. Each primitive is a node in the tree where the leaves of a node are the inputs to the parent node. When we evaluate each individual we simply compile the primitive tree from its leaves to its root node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source code for PrimitiveTree and gp.compile can be found here: https://github.com/DEAP/deap/blob/master/deap/gp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will initialize a primitive set and add all the primitives our trees can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = gp.PrimitiveSet(\"MAIN\", arity=1)\n",
    "pset.addPrimitive(np.add, arity=2)\n",
    "pset.addPrimitive(np.subtract, arity=2)\n",
    "pset.addPrimitive(np.multiply, arity=2)\n",
    "pset.addPrimitive(np.negative, arity=1)\n",
    "pset.renameArguments(ARG0='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added several mathematical operators to our primitive set. We also renamed the default first argument name in DEAP to x instead of ARG0. The arity parameter we defined specifies the amount of arguments each primitive takes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add at least two new primitives in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset.addPrimitive()\n",
    "pset.addPrimitive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define our toolbox, individual, population, and compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now this format should look familar to you. The major difference here is the \"expr\" function we defined. gp.genHaldandHalf returns a primitive tree based on a primitive set and a minimum and maximum tree depth. In this case the primitive set is the one we defined earlier, the minimum depth is 1, and the maxmimum depth is 2. I encourage you to change the minimum and maximum depth and observe the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define our evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalSymbReg(individual, points, pset):\n",
    "    func = gp.compile(expr=individual, pset=pset)\n",
    "    sqerrors = (func(points)-(points**4 + points**3 + points**2 + points))**2\n",
    "    return (np.sqrt(np.sum(sqerrors) / len(points)),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our primitive tree we first compile the tree into a function. Then, we calculate the function and determine the mean squared error between the function we compile and the actual function we are trying to generate. We are optimizing the function we are generating by minimizing mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not trying to fit a function to data though. We are trying to generate a specific output. We already know what the ideal function is and our primitive set contains all the primitives used by the ideal function. However, you could think of genetic programming as finding the best combination of primitives given objectives to minimize or maximize. This means we care a lot less about data than machine learning and care more about objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will register our genetic operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"evaluate\", evalSymbReg, points=np.linspace(-1, 1, 1000), pset=pset)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add at least one more mutation method in the code cell below and try out this mutation method in the evolutionary loop found further below.\n",
    "\n",
    "You can find more GP mutations in the DEAP source code here: https://github.com/DEAP/deap/blob/master/deap/gp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can optionally add tree height contraints to our mutation and crossover functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will program the main evolutionary algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = range(40)\n",
    "avg_list = []\n",
    "max_list = []\n",
    "min_list = []\n",
    "\n",
    "pop = toolbox.population(n=300)\n",
    "\n",
    "# Evaluate the entire population\n",
    "fitnesses = list(map(toolbox.evaluate, pop))\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "# Begin the evolution\n",
    "for g in gen:\n",
    "    print(\"-- Generation %i --\" % g)\n",
    "\n",
    "    # Select the next generation individuals\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < 0.5:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < 0.2:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Replace population\n",
    "    pop[:] = offspring\n",
    "\n",
    "    # Gather all the fitnesses in one list and print the stats\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "    g_max = max(fits)\n",
    "    g_min = min(fits)\n",
    "        \n",
    "    avg_list.append(mean)\n",
    "    max_list.append(g_max)\n",
    "    min_list.append(g_min)\n",
    "\n",
    "    print(\"  Min %s\" % g_min)\n",
    "    print(\"  Max %s\" % g_max)\n",
    "    print(\"  Avg %s\" % mean)\n",
    "    print(\"  Std %s\" % std)\n",
    "\n",
    "print(\"-- End of (successful) evolution --\")\n",
    "\n",
    "best_ind = tools.selBest(pop, 1)[0]\n",
    "print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format above should look familar to you. It's the same evolutionary loop we used in Lab 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the best individual above is different from the list format of our previous problems. The individual is printed out in a tree format being read from left to right. There are ways to visualize the individual tree. However, this lab will not cover how to visualize the individual. I encourage you to look up networkx and graphviz if you are interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gen, avg_list, label=\"average\")\n",
    "plt.plot(gen, min_list, label=\"minimum\")\n",
    "plt.plot(gen, max_list, label=\"maximum\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the parameters of the above genetic programming to improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Objective Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Symbolic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate multi-objective optimization, we are going to modify our code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create new fitness and individual classes for a multiobjective problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,-1.0))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will minimize two objectives, mean squared error and the size of our tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to add three new primitives to our primitive set and set a seed for randomization. We will also reinitialize our toolbox to make sure all of our tools work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(25)\n",
    "\n",
    "pset = gp.PrimitiveSet(\"MAIN\", arity=1)\n",
    "pset.addPrimitive(np.add, arity=2)\n",
    "pset.addPrimitive(np.subtract, arity=2)\n",
    "pset.addPrimitive(np.multiply, arity=2)\n",
    "pset.addPrimitive(np.negative, arity=1)\n",
    "pset.addPrimitive(np.sin, arity=1)\n",
    "pset.addPrimitive(np.cos, arity=1)\n",
    "pset.addPrimitive(np.tan, arity=1)\n",
    "pset.renameArguments(ARG0='x')\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reinitialized our primitive set and set a seed for randomization to ensure everyone produces the same results. The three primitives we added will be used in our updated evaluation function in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add another objective to our evaluation function and change the problem into a more difficult one. We will also reinitialize the rest of our toolbox functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalSymbReg(individual, points, pset):\n",
    "    func = gp.compile(expr=individual, pset=pset)\n",
    "    sqerrors = (func(points)-(np.negative(points) + np.sin(points**2) + np.tan(points**3) - np.cos(points)))**2\n",
    "\n",
    "    return (np.sqrt(np.sum(sqerrors) / len(points)), len(individual))\n",
    "\n",
    "\n",
    "toolbox.register(\"evaluate\", evalSymbReg, points=np.linspace(-1, 1, 1000), pset=pset)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our symbolic regression problem has been replaced with a much harder equation to solve. This is designed to show more evolution over time than the previous problem. This problem will not be solved within 100 iterations. We also return the length of the individual tree, which returns the amount of nodes in that individual tree. We will make changes to our evolutionary process to optimize both objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in this example we will first create a visualization of our objective space to help illustrate the pareto dominance we will use later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define our pareto dominance function. We will use this function when we visualize our objective space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pareto_dominance(ind1, ind2):\n",
    "    not_equal = False\n",
    "    for value_1, value_2 in zip(ind1.fitness.values, ind2.fitness.values):\n",
    "        if value_1 > value_2:\n",
    "            return False\n",
    "        elif value_1 < value_2:\n",
    "            not_equal = True\n",
    "    return not_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pareto dominance function returns true if the first individual dominates the second individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will initialize a random population of 300 individuals and initialize one separate individual for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop = toolbox.population(n=300)\n",
    "\n",
    "fitnesses = list(map(toolbox.evaluate, pop))\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "a_given_individual = toolbox.population(n=1)[0]\n",
    "a_given_individual.fitness.values = toolbox.evaluate(a_given_individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will sort our population by pareto dominance in comparison to the separate individual we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dominated = [ind for ind in pop if pareto_dominance(a_given_individual, ind)]\n",
    "dominators = [ind for ind in pop if pareto_dominance(ind, a_given_individual)]\n",
    "others = [ind for ind in pop if not ind in dominated and not ind in dominators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will plot our objective space using our sorted population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in dominators: plt.plot(ind.fitness.values[0], ind.fitness.values[1], 'r.', alpha=0.7)\n",
    "for ind in dominated: plt.plot(ind.fitness.values[0], ind.fitness.values[1], 'g.', alpha=0.7)\n",
    "for ind in others: plt.plot(ind.fitness.values[0], ind.fitness.values[1], 'k.', alpha=0.7, ms=3)\n",
    "plt.plot(a_given_individual.fitness.values[0], a_given_individual.fitness.values[1], 'bo', ms=6);\n",
    "plt.xlabel('Mean Squared Error');plt.ylabel('Tree Size');\n",
    "plt.title('Objective space');\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue point is the given individual we set aside and compared all the other individuals to. The black points are uncomparable, the green points are dominated by the given individual, and the red points dominate the given individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in this visualization how the individuals dominating our pareto front are closer to the bottom right because they have the lowest MSE and tree size. Our goal is to minimize both objectives and have an individual as close to the bottom right as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more in-depth look at DEAP, pareto fronts, and pareto dominance can be found here: https://github.com/lmarti/evolutionary-computation-course/blob/master/AEC.06%20-%20Evolutionary%20Multi-Objective%20Optimization.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define and run the main evolutionary algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGEN = 50\n",
    "MU = 50\n",
    "LAMBDA = 100\n",
    "CXPB = 0.5\n",
    "MUTPB = 0.2\n",
    "\n",
    "pop = toolbox.population(n=MU)\n",
    "hof = tools.ParetoFront()\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean, axis=0)\n",
    "stats.register(\"std\", np.std, axis=0)\n",
    "stats.register(\"min\", np.min, axis=0)\n",
    "stats.register(\"max\", np.max, axis=0)\n",
    "\n",
    "pop, logbook = algorithms.eaMuPlusLambda(pop, toolbox, MU, LAMBDA, CXPB, MUTPB, NGEN, stats,\n",
    "                          halloffame=hof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will plot the results of our run and display the best individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best individual is: %s\\nwith fitness: %s\" % (hof[0], hof[0].fitness))\n",
    "gen, avg, min_, max_ = logbook.select(\"gen\", \"avg\", \"min\", \"max\")\n",
    "plt.plot(gen, avg, label=\"average\")\n",
    "plt.plot(gen, min_, label=\"minimum\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph above, the orange and red plots represent tree size and the blue and green plots represent MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we made use of DEAP's efficient implementations of pareto dominance and evolutionary algorithms. We used DEAP's Mu plus Lambda evolutionary algorithm. This adds two new parameters than the evolutionary loop we are used to, mu and lambda. Mu is the number of individuals to select for the next generation. Lambda is the number of children to produce at each generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, we can see two trends. The size of our primitive trees raises over time, and our mean squared error quickly drops to between 0 and 1 within the first few generations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, that plot does not accurately represent how well our population is doing on both objectives. We can use a visualization of our objective space to show our pareto front and accurately represent how well our population is doing on both objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will visualize our objective space and pareto front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split fitness values into separate lists\"\"\"\n",
    "fitness_1 = [ind.fitness.values[0] for ind in hof]\n",
    "fitness_2 = [ind.fitness.values[1] for ind in hof]\n",
    "pop_1 = [ind.fitness.values[0] for ind in pop]\n",
    "pop_2 = [ind.fitness.values[1] for ind in pop]\n",
    "\n",
    "'''Print dominated population for debugging'''\n",
    "# for ind in pop:\n",
    "#     print(ind.fitness)\n",
    "\n",
    "plt.scatter(pop_1, pop_2, color='b')\n",
    "plt.scatter(fitness_1, fitness_2, color='r')\n",
    "plt.plot(fitness_1, fitness_2, color='r', drawstyle='steps-post')\n",
    "plt.xlabel(\"Mean Squared Error\")\n",
    "plt.ylabel(\"Tree Size\")\n",
    "plt.title(\"Pareto Front\")\n",
    "plt.show()\n",
    "\n",
    "f1 = np.array(fitness_1)\n",
    "f2 = np.array(fitness_2)\n",
    "\n",
    "\"\"\"Calculate area under curve with least squares method\"\"\"\n",
    "print(\"Area Under Curve: %s\" % (np.sum(np.abs(np.diff(f1))*f2[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEAP's pareto front hall of fame gives us a list of the nondominated individuals after our evolution. We use that list and the last population to visualize our pareto front."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the performance of our pareto front we use the area under the curve of the pareto front seen in the visualization. The lower our AUC is, the better our pareto front is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a version of the genetic programming problem above which produces at least a 25% decrease in the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strongly Typed Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: You are not required to run the code in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will highlight more features of DEAP and genetic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: http://deap.readthedocs.io/en/master/tutorials/advanced/gp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def if_then_else(input, output1, output2):\n",
    "    return output1 if input else output2\n",
    "\n",
    "pset = PrimitiveSetTyped(\"main\", [bool, float], float)\n",
    "pset.addPrimitive(operator.xor, [bool, bool], bool)\n",
    "pset.addPrimitive(operator.mul, [float, float], float)\n",
    "pset.addPrimitive(if_then_else, [bool, float, float], float)\n",
    "pset.addTerminal(3.0, float)\n",
    "pset.addTerminal(1, bool)\n",
    "\n",
    "pset.renameArguments(ARG0=\"x\")\n",
    "pset.renameArguments(ARG1=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we defined strongly typed primitives and terminals. Terminals are pre-defined constants for our individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we defined our strongly typed primitive set with the PrimitiveSetTyped() method. The first argument defines the name of the primitive set. The second argument defines the input (leaf) nodes of each individual tree, and the third argument defines the output of each individual tree. In this case our leaf nodes consist of Booleans and floats put together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding primitives follows the same structure of defining inputs and then outputs. For terminals, we define the value of the terminal and then its type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/images/trees.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree above on the left is a valid tree based on the primitive set we defined.\n",
    "The tree on the right is invalid because XOR is given a float not equal to 1 or 0 instead of a Boolean value.\n",
    "\n",
    "We have to be careful to not define primitives and terminals our trees cannot produce. This will lead to errors when we evolve our population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ephemeral Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ephermeral constants are terminals generated by a function instead of pre-defined values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pset.addEphemeralConstant(lambda: random.randint(-10, 10), int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloat Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we will cover is limiting tree size and bloat control. DEAP trees can only have a maximum depth of 91 due to limitations in Python's parser. There are also many examples of GP problems where individuals bloat over time and increase in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent this, we can use static limits like the code shown above, set an objective to minimize tree size, and modify our evaluation function to give bloated trees worse fitness values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
