{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation (EMADE Implementation of Stocks Dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Run all the code cells below in order to ensure everything runs correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by installing the libraries/packages necessary for this specific dataset and EMADE. In my case, I needed to install Tensorflow and Keras. In order to do so, run cmd *AS ADMINISTRATOR* and then type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only run this code if you do not have these libraries already installed.\n",
    "\n",
    "# pip install tensorflow\n",
    "# pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary libraries/packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import shutil\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line is incase your code throws annoying warnings later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **Open the  all_stocks_5yr  excel/csv file and look at the data.**          \n",
    "   ** It will help you understand and visualize the following steps.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read your data (excel, csv, etc.) and select the specific rows you want to work with. In this case, I have multiple stocks, but will only be showing you the first one (MMM). MMM takes up the first 1258 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Open   High    Low  Close     Volume Name\n",
      "0  8/13/2012  92.29  92.59  91.74  92.40  2075391.0  MMM\n",
      "1  8/14/2012  92.36  92.50  92.01  92.30  1843476.0  MMM\n",
      "2  8/15/2012  92.00  92.74  91.94  92.54  1983395.0  MMM\n",
      "3  8/16/2012  92.75  93.87  92.21  93.74  3395145.0  MMM\n",
      "4  8/17/2012  93.93  94.30  93.59  94.24  3069513.0  MMM\n",
      "(606801, 7)\n",
      "(1258, 7)\n",
      "           Date    Open    High     Low   Close     Volume Name\n",
      "0     8/13/2012   92.29   92.59   91.74   92.40  2075391.0  MMM\n",
      "1     8/14/2012   92.36   92.50   92.01   92.30  1843476.0  MMM\n",
      "2     8/15/2012   92.00   92.74   91.94   92.54  1983395.0  MMM\n",
      "3     8/16/2012   92.75   93.87   92.21   93.74  3395145.0  MMM\n",
      "4     8/17/2012   93.93   94.30   93.59   94.24  3069513.0  MMM\n",
      "5     8/20/2012   94.00   94.17   93.55   93.89  1640008.0  MMM\n",
      "6     8/21/2012   93.98   94.10   92.99   93.21  2302988.0  MMM\n",
      "7     8/22/2012   92.56   93.36   92.43   92.68  2463908.0  MMM\n",
      "8     8/23/2012   92.65   92.68   91.79   91.98  1823757.0  MMM\n",
      "9     8/24/2012   92.03   92.97   91.94   92.83  1945796.0  MMM\n",
      "10    8/27/2012   92.92   92.97   92.40   92.59  1879969.0  MMM\n",
      "11    8/28/2012   92.36   92.77   92.20   92.30  1913066.0  MMM\n",
      "12    8/29/2012   92.50   92.80   92.30   92.43  1735933.0  MMM\n",
      "13    8/30/2012   92.05   92.15   91.30   91.76  1729576.0  MMM\n",
      "14    8/31/2012   92.44   93.00   91.90   92.60  1917265.0  MMM\n",
      "15     9/4/2012   92.03   92.33   91.10   91.68  2532261.0  MMM\n",
      "16     9/5/2012   91.92   91.99   91.11   91.75  2985428.0  MMM\n",
      "17     9/6/2012   92.37   93.38   92.06   93.28  3223309.0  MMM\n",
      "18     9/7/2012   93.38   93.65   92.70   92.82  3215341.0  MMM\n",
      "19    9/10/2012   92.27   92.31   90.61   90.67  6356086.0  MMM\n",
      "20    9/11/2012   90.73   91.59   90.65   91.17  2403421.0  MMM\n",
      "21    9/12/2012   91.60   91.66   90.46   90.81  2409574.0  MMM\n",
      "22    9/13/2012   90.92   92.43   90.46   92.06  2734203.0  MMM\n",
      "23    9/14/2012   92.86   93.98   92.56   93.98  4993059.0  MMM\n",
      "24    9/17/2012   93.66   94.09   93.49   93.78  3290255.0  MMM\n",
      "25    9/18/2012   93.78   93.99   93.22   93.43  2477444.0  MMM\n",
      "26    9/19/2012   92.88   94.06   92.73   93.63  2723431.0  MMM\n",
      "27    9/20/2012   93.20   93.63   92.91   93.58  2075529.0  MMM\n",
      "28    9/21/2012   94.06   94.07   92.94   93.21  9551168.0  MMM\n",
      "29    9/24/2012   92.85   94.09   92.76   93.73  3037401.0  MMM\n",
      "...         ...     ...     ...     ...     ...        ...  ...\n",
      "1228  6/30/2017  209.91  209.91  207.85  208.19  1769958.0  MMM\n",
      "1229   7/3/2017  209.14  210.34  208.75  209.83  1040334.0  MMM\n",
      "1230   7/5/2017  210.00  210.24  209.41  209.76  1065328.0  MMM\n",
      "1231   7/6/2017  209.05  209.72  207.89  208.02  1189853.0  MMM\n",
      "1232   7/7/2017  208.50  210.15  208.04  209.59  1531004.0  MMM\n",
      "1233  7/10/2017  209.60  211.74  208.99  210.49  1308603.0  MMM\n",
      "1234  7/11/2017  210.41  211.20  208.00  209.66  1268059.0  MMM\n",
      "1235  7/12/2017  210.91  212.78  210.27  211.30  1447890.0  MMM\n",
      "1236  7/13/2017  211.20  212.00  210.18  211.09  1138838.0  MMM\n",
      "1237  7/14/2017  211.52  212.24  210.63  211.77  1061971.0  MMM\n",
      "1238  7/17/2017  212.20  212.20  210.59  211.68  1311262.0  MMM\n",
      "1239  7/18/2017  210.68  211.52  210.30  211.31  1562553.0  MMM\n",
      "1240  7/19/2017  211.51  212.10  211.17  212.10   825309.0  MMM\n",
      "1241  7/20/2017  212.21  213.41  212.06  212.45  1347433.0  MMM\n",
      "1242  7/21/2017  211.65  211.84  209.48  211.16  2246238.0  MMM\n",
      "1243  7/24/2017  211.20  211.66  210.00  210.00  2165186.0  MMM\n",
      "1244  7/25/2017  202.65  204.50  197.17  199.39  6593035.0  MMM\n",
      "1245  7/26/2017  200.45  201.15  198.55  199.03  2922097.0  MMM\n",
      "1246  7/27/2017  199.14  200.56  197.67  200.05  2175148.0  MMM\n",
      "1247  7/28/2017  200.79  201.04  198.69  199.72  1488022.0  MMM\n",
      "1248  7/31/2017     NaN  201.66     NaN  201.17  1833625.0  MMM\n",
      "1249   8/1/2017  202.29  203.31  201.76  203.18  2015108.0  MMM\n",
      "1250   8/2/2017  203.19  205.60  202.82  205.41  2029646.0  MMM\n",
      "1251   8/3/2017  205.91  207.64  205.12  207.62  2054236.0  MMM\n",
      "1252   8/4/2017  207.95  208.61  206.11  207.65  1522668.0  MMM\n",
      "1253   8/7/2017  207.90  208.40  206.68  207.44  1172563.0  MMM\n",
      "1254   8/8/2017  206.83  207.89  205.69  206.43  1856282.0  MMM\n",
      "1255   8/9/2017  206.69  207.91  205.59  206.48  1622213.0  MMM\n",
      "1256  8/10/2017  205.62  207.16  205.18  206.23  1571545.0  MMM\n",
      "1257  8/11/2017  206.85  206.85  205.63  205.98  1452811.0  MMM\n",
      "\n",
      "[1258 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"all_stocks_5yr.csv\")\n",
    "\n",
    "# Print first 5 examples\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "data = data.drop(data.index[1258:])\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign your labels variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------LABELS-------------------------------\n",
      "(1258, 1)\n",
      "       Close\n",
      "0      92.40\n",
      "1      92.30\n",
      "2      92.54\n",
      "3      93.74\n",
      "4      94.24\n",
      "5      93.89\n",
      "6      93.21\n",
      "7      92.68\n",
      "8      91.98\n",
      "9      92.83\n",
      "10     92.59\n",
      "11     92.30\n",
      "12     92.43\n",
      "13     91.76\n",
      "14     92.60\n",
      "15     91.68\n",
      "16     91.75\n",
      "17     93.28\n",
      "18     92.82\n",
      "19     90.67\n",
      "20     91.17\n",
      "21     90.81\n",
      "22     92.06\n",
      "23     93.98\n",
      "24     93.78\n",
      "25     93.43\n",
      "26     93.63\n",
      "27     93.58\n",
      "28     93.21\n",
      "29     93.73\n",
      "...      ...\n",
      "1228  208.19\n",
      "1229  209.83\n",
      "1230  209.76\n",
      "1231  208.02\n",
      "1232  209.59\n",
      "1233  210.49\n",
      "1234  209.66\n",
      "1235  211.30\n",
      "1236  211.09\n",
      "1237  211.77\n",
      "1238  211.68\n",
      "1239  211.31\n",
      "1240  212.10\n",
      "1241  212.45\n",
      "1242  211.16\n",
      "1243  210.00\n",
      "1244  199.39\n",
      "1245  199.03\n",
      "1246  200.05\n",
      "1247  199.72\n",
      "1248  201.17\n",
      "1249  203.18\n",
      "1250  205.41\n",
      "1251  207.62\n",
      "1252  207.65\n",
      "1253  207.44\n",
      "1254  206.43\n",
      "1255  206.48\n",
      "1256  206.23\n",
      "1257  205.98\n",
      "\n",
      "[1258 rows x 1 columns]\n",
      "----------------------------LABELS-------------------------------\n"
     ]
    }
   ],
   "source": [
    "labels = data[[\"Close\"]]\n",
    "print(\"----------------------------LABELS-------------------------------\")\n",
    "print(labels.shape)\n",
    "print(labels)\n",
    "print(\"----------------------------LABELS-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the labels variable so that you replace their values with 0 or 1. In our case, we are determining if the 'Close' price is greater or less than the 'Close' price from the previous day. \n",
    "\n",
    "If the price is greater than the day before, we will put a 1. If it less, we will put a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 1)\n",
      "      Close\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "5       0.0\n",
      "6       0.0\n",
      "7       0.0\n",
      "8       0.0\n",
      "9       1.0\n",
      "10      0.0\n",
      "11      0.0\n",
      "12      1.0\n",
      "13      0.0\n",
      "14      1.0\n",
      "15      0.0\n",
      "16      1.0\n",
      "17      1.0\n",
      "18      0.0\n",
      "19      0.0\n",
      "20      1.0\n",
      "21      0.0\n",
      "22      1.0\n",
      "23      1.0\n",
      "24      0.0\n",
      "25      0.0\n",
      "26      1.0\n",
      "27      0.0\n",
      "28      0.0\n",
      "29      1.0\n",
      "...     ...\n",
      "1228    1.0\n",
      "1229    1.0\n",
      "1230    0.0\n",
      "1231    0.0\n",
      "1232    1.0\n",
      "1233    1.0\n",
      "1234    0.0\n",
      "1235    1.0\n",
      "1236    0.0\n",
      "1237    1.0\n",
      "1238    0.0\n",
      "1239    0.0\n",
      "1240    1.0\n",
      "1241    1.0\n",
      "1242    0.0\n",
      "1243    0.0\n",
      "1244    0.0\n",
      "1245    0.0\n",
      "1246    1.0\n",
      "1247    0.0\n",
      "1248    1.0\n",
      "1249    1.0\n",
      "1250    1.0\n",
      "1251    1.0\n",
      "1252    1.0\n",
      "1253    0.0\n",
      "1254    0.0\n",
      "1255    1.0\n",
      "1256    0.0\n",
      "1257    0.0\n",
      "\n",
      "[1258 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "labels.loc[labels.Close >= labels.Close.shift(), 'Close'] = 1\n",
    "labels.loc[labels.Close != 1, 'Close'] = 0\n",
    "\n",
    "\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Drop columns that you don't need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date   Close     Volume Name\n",
      "0     8/13/2012   92.40  2075391.0  MMM\n",
      "1     8/14/2012   92.30  1843476.0  MMM\n",
      "2     8/15/2012   92.54  1983395.0  MMM\n",
      "3     8/16/2012   93.74  3395145.0  MMM\n",
      "4     8/17/2012   94.24  3069513.0  MMM\n",
      "5     8/20/2012   93.89  1640008.0  MMM\n",
      "6     8/21/2012   93.21  2302988.0  MMM\n",
      "7     8/22/2012   92.68  2463908.0  MMM\n",
      "8     8/23/2012   91.98  1823757.0  MMM\n",
      "9     8/24/2012   92.83  1945796.0  MMM\n",
      "10    8/27/2012   92.59  1879969.0  MMM\n",
      "11    8/28/2012   92.30  1913066.0  MMM\n",
      "12    8/29/2012   92.43  1735933.0  MMM\n",
      "13    8/30/2012   91.76  1729576.0  MMM\n",
      "14    8/31/2012   92.60  1917265.0  MMM\n",
      "15     9/4/2012   91.68  2532261.0  MMM\n",
      "16     9/5/2012   91.75  2985428.0  MMM\n",
      "17     9/6/2012   93.28  3223309.0  MMM\n",
      "18     9/7/2012   92.82  3215341.0  MMM\n",
      "19    9/10/2012   90.67  6356086.0  MMM\n",
      "20    9/11/2012   91.17  2403421.0  MMM\n",
      "21    9/12/2012   90.81  2409574.0  MMM\n",
      "22    9/13/2012   92.06  2734203.0  MMM\n",
      "23    9/14/2012   93.98  4993059.0  MMM\n",
      "24    9/17/2012   93.78  3290255.0  MMM\n",
      "25    9/18/2012   93.43  2477444.0  MMM\n",
      "26    9/19/2012   93.63  2723431.0  MMM\n",
      "27    9/20/2012   93.58  2075529.0  MMM\n",
      "28    9/21/2012   93.21  9551168.0  MMM\n",
      "29    9/24/2012   93.73  3037401.0  MMM\n",
      "...         ...     ...        ...  ...\n",
      "1228  6/30/2017  208.19  1769958.0  MMM\n",
      "1229   7/3/2017  209.83  1040334.0  MMM\n",
      "1230   7/5/2017  209.76  1065328.0  MMM\n",
      "1231   7/6/2017  208.02  1189853.0  MMM\n",
      "1232   7/7/2017  209.59  1531004.0  MMM\n",
      "1233  7/10/2017  210.49  1308603.0  MMM\n",
      "1234  7/11/2017  209.66  1268059.0  MMM\n",
      "1235  7/12/2017  211.30  1447890.0  MMM\n",
      "1236  7/13/2017  211.09  1138838.0  MMM\n",
      "1237  7/14/2017  211.77  1061971.0  MMM\n",
      "1238  7/17/2017  211.68  1311262.0  MMM\n",
      "1239  7/18/2017  211.31  1562553.0  MMM\n",
      "1240  7/19/2017  212.10   825309.0  MMM\n",
      "1241  7/20/2017  212.45  1347433.0  MMM\n",
      "1242  7/21/2017  211.16  2246238.0  MMM\n",
      "1243  7/24/2017  210.00  2165186.0  MMM\n",
      "1244  7/25/2017  199.39  6593035.0  MMM\n",
      "1245  7/26/2017  199.03  2922097.0  MMM\n",
      "1246  7/27/2017  200.05  2175148.0  MMM\n",
      "1247  7/28/2017  199.72  1488022.0  MMM\n",
      "1248  7/31/2017  201.17  1833625.0  MMM\n",
      "1249   8/1/2017  203.18  2015108.0  MMM\n",
      "1250   8/2/2017  205.41  2029646.0  MMM\n",
      "1251   8/3/2017  207.62  2054236.0  MMM\n",
      "1252   8/4/2017  207.65  1522668.0  MMM\n",
      "1253   8/7/2017  207.44  1172563.0  MMM\n",
      "1254   8/8/2017  206.43  1856282.0  MMM\n",
      "1255   8/9/2017  206.48  1622213.0  MMM\n",
      "1256  8/10/2017  206.23  1571545.0  MMM\n",
      "1257  8/11/2017  205.98  1452811.0  MMM\n",
      "\n",
      "[1258 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(\"Open\", axis=1)\n",
    "data = data.drop(\"High\", axis=1)\n",
    "data = data.drop(\"Low\", axis=1)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the text (the stock 'Name' column) in a new variable and remove it from the original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM', 'MMM']\n",
      "           Date   Close     Volume\n",
      "0     8/13/2012   92.40  2075391.0\n",
      "1     8/14/2012   92.30  1843476.0\n",
      "2     8/15/2012   92.54  1983395.0\n",
      "3     8/16/2012   93.74  3395145.0\n",
      "4     8/17/2012   94.24  3069513.0\n",
      "5     8/20/2012   93.89  1640008.0\n",
      "6     8/21/2012   93.21  2302988.0\n",
      "7     8/22/2012   92.68  2463908.0\n",
      "8     8/23/2012   91.98  1823757.0\n",
      "9     8/24/2012   92.83  1945796.0\n",
      "10    8/27/2012   92.59  1879969.0\n",
      "11    8/28/2012   92.30  1913066.0\n",
      "12    8/29/2012   92.43  1735933.0\n",
      "13    8/30/2012   91.76  1729576.0\n",
      "14    8/31/2012   92.60  1917265.0\n",
      "15     9/4/2012   91.68  2532261.0\n",
      "16     9/5/2012   91.75  2985428.0\n",
      "17     9/6/2012   93.28  3223309.0\n",
      "18     9/7/2012   92.82  3215341.0\n",
      "19    9/10/2012   90.67  6356086.0\n",
      "20    9/11/2012   91.17  2403421.0\n",
      "21    9/12/2012   90.81  2409574.0\n",
      "22    9/13/2012   92.06  2734203.0\n",
      "23    9/14/2012   93.98  4993059.0\n",
      "24    9/17/2012   93.78  3290255.0\n",
      "25    9/18/2012   93.43  2477444.0\n",
      "26    9/19/2012   93.63  2723431.0\n",
      "27    9/20/2012   93.58  2075529.0\n",
      "28    9/21/2012   93.21  9551168.0\n",
      "29    9/24/2012   93.73  3037401.0\n",
      "...         ...     ...        ...\n",
      "1228  6/30/2017  208.19  1769958.0\n",
      "1229   7/3/2017  209.83  1040334.0\n",
      "1230   7/5/2017  209.76  1065328.0\n",
      "1231   7/6/2017  208.02  1189853.0\n",
      "1232   7/7/2017  209.59  1531004.0\n",
      "1233  7/10/2017  210.49  1308603.0\n",
      "1234  7/11/2017  209.66  1268059.0\n",
      "1235  7/12/2017  211.30  1447890.0\n",
      "1236  7/13/2017  211.09  1138838.0\n",
      "1237  7/14/2017  211.77  1061971.0\n",
      "1238  7/17/2017  211.68  1311262.0\n",
      "1239  7/18/2017  211.31  1562553.0\n",
      "1240  7/19/2017  212.10   825309.0\n",
      "1241  7/20/2017  212.45  1347433.0\n",
      "1242  7/21/2017  211.16  2246238.0\n",
      "1243  7/24/2017  210.00  2165186.0\n",
      "1244  7/25/2017  199.39  6593035.0\n",
      "1245  7/26/2017  199.03  2922097.0\n",
      "1246  7/27/2017  200.05  2175148.0\n",
      "1247  7/28/2017  199.72  1488022.0\n",
      "1248  7/31/2017  201.17  1833625.0\n",
      "1249   8/1/2017  203.18  2015108.0\n",
      "1250   8/2/2017  205.41  2029646.0\n",
      "1251   8/3/2017  207.62  2054236.0\n",
      "1252   8/4/2017  207.65  1522668.0\n",
      "1253   8/7/2017  207.44  1172563.0\n",
      "1254   8/8/2017  206.43  1856282.0\n",
      "1255   8/9/2017  206.48  1622213.0\n",
      "1256  8/10/2017  206.23  1571545.0\n",
      "1257  8/11/2017  205.98  1452811.0\n",
      "\n",
      "[1258 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "text = data[[\"Name\"]].values\n",
    "data = data.drop(\"Name\", axis=1)\n",
    "\n",
    "text_list = []\n",
    "for i in text:\n",
    "    text_list.append(i[0])\n",
    "    \n",
    "print(text_list)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the text and data values into numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM' 'MMM' 'MMM' ..., 'MMM' 'MMM' 'MMM']\n",
      "[['8/13/2012' 92.4 2075391.0]\n",
      " ['8/14/2012' 92.3 1843476.0]\n",
      " ['8/15/2012' 92.54 1983395.0]\n",
      " ..., \n",
      " ['8/9/2017' 206.48 1622213.0]\n",
      " ['8/10/2017' 206.23 1571545.0]\n",
      " ['8/11/2017' 205.98 1452811.0]]\n"
     ]
    }
   ],
   "source": [
    "text_array = np.array(text_list)\n",
    "data_array = data.values\n",
    "\n",
    "print(text_array)\n",
    "print(data_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will split our data into train and test data & concat the input data and labels together to fit EMADE's format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------TRAIN-------------------------------\n",
      "(842, 4)\n",
      "[['8/13/2012' 92.4 2075391.0 0.0]\n",
      " ['8/14/2012' 92.3 1843476.0 0.0]\n",
      " ['8/15/2012' 92.54 1983395.0 1.0]\n",
      " ..., \n",
      " ['12/14/2015' 157.63 3448686.0 1.0]\n",
      " ['12/15/2015' 148.13 8645905.0 0.0]\n",
      " ['12/16/2015' 149.95 4774134.0 1.0]]\n",
      "----------------------------TRAIN-------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------TEST-------------------------------\n",
      "(416, 4)\n",
      "[['12/17/2015' 148.85 3053902.0 0.0]\n",
      " ['12/18/2015' 146.92 5736432.0 0.0]\n",
      " ['12/21/2015' 147.48 2284411.0 1.0]\n",
      " ..., \n",
      " ['8/9/2017' 206.48 1622213.0 1.0]\n",
      " ['8/10/2017' 206.23 1571545.0 0.0]\n",
      " ['8/11/2017' 205.98 1452811.0 0.0]]\n",
      "----------------------------TEST-------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_array, labels.values, test_size=0.33, shuffle=False)\n",
    "\n",
    "data_train = np.concatenate((X_train, y_train), axis=1)\n",
    "data_test = np.concatenate((X_test, y_test), axis=1)\n",
    "\n",
    "print(\"----------------------------TRAIN-------------------------------\")\n",
    "print(data_train.shape)\n",
    "print(data_train)\n",
    "print(\"----------------------------TRAIN-------------------------------\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"----------------------------TEST-------------------------------\")\n",
    "print(data_test.shape)\n",
    "print(data_test)\n",
    "print(\"----------------------------TEST-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training and test data with 67% as training and 33% as testing data. Then, we append the labels columns to the end of the input data columns to put the data into the format EMADE expects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
