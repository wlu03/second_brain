{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dcd4e44",
   "metadata": {},
   "source": [
    "# Human in the Loop\n",
    "\n",
    "Ability to replace messages. It looks for msg with the same id to replace them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f160db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c146dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77540faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_messages(left: list[AnyMessage], right: list[AnyMessage]) -> list[AnyMessage]:\n",
    "    ## assign ids to message that dont have them\n",
    "    \n",
    "    for message in right: \n",
    "        if not message.id:\n",
    "            message.id = str(uuid4())\n",
    "    ## merge the new messages with the existing messages\n",
    "    merged = left.copy()\n",
    "    for message in right: \n",
    "        for idx, existing in enumerate(merged):\n",
    "            # replace any existing messages with the same id\n",
    "            if existing.id == message.id:\n",
    "                merged[i] = message\n",
    "                break\n",
    "        else:\n",
    "            # append any exisitng messages with the same id\n",
    "            merged.append(message)\n",
    "    return merged\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], reduce_messages]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b3ab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8l/9f8bkrp10_j_nv1019x4c4lr0000gn/T/ipykernel_58500/4289725543.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tool = TavilySearchResults(max_results=2)\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ee06b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, system=\"\", checkpointer=None):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\",    self.call_openai, defer=True)\n",
    "        graph.add_node(\"action\", self.take_action, defer=True)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(\n",
    "            checkpointer=checkpointer,\n",
    "            interrupt_before=[\"action\"]  ## this is passed before the action node (where tools are called)\n",
    "                                         ## this is where the human interrupts any tools that might not want to be called\n",
    "        )\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        print(state)\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d84982de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b17d25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Whats the weather in SF?', additional_kwargs={}, response_metadata={}, id='dbad97a8-923b-4e78-b1bb-6de10fe8972d'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qFA1P8EFaiQpiRgQAWoJvqBH', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 152, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bqn1FhD3JAHQtpvkHQwfO4b5VvFwN', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6fe9d5ee-2b00-4580-a971-a5f97bd883dc-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_qFA1P8EFaiQpiRgQAWoJvqBH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 22, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qFA1P8EFaiQpiRgQAWoJvqBH', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 152, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bqn1FhD3JAHQtpvkHQwfO4b5VvFwN', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6fe9d5ee-2b00-4580-a971-a5f97bd883dc-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_qFA1P8EFaiQpiRgQAWoJvqBH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 22, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "()\n",
      "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in SF?', additional_kwargs={}, response_metadata={}, id='dbad97a8-923b-4e78-b1bb-6de10fe8972d'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qFA1P8EFaiQpiRgQAWoJvqBH', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 152, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bqn1FhD3JAHQtpvkHQwfO4b5VvFwN', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6fe9d5ee-2b00-4580-a971-a5f97bd883dc-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_qFA1P8EFaiQpiRgQAWoJvqBH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 22, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=('action',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f05b737-2fd1-6712-8001-f4c37f4f7327'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}, 'thread_id': '1'}, created_at='2025-07-07T20:46:25.704104+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f05b737-2503-66c8-8000-801472adc4ea'}}, tasks=(PregelTask(id='4d1d3b9d-4003-9099-e493-c15ef2786d31', name='action', path=('__pregel_pull', 'action'), error=None, interrupts=(), state=None, result=None),), interrupts=())\n",
      "('action',)\n"
     ]
    }
   ],
   "source": [
    "with SqliteSaver.from_conn_string(\":memory:\") as memory:\n",
    "    abot = Agent(model, [tool], system=prompt, checkpointer=memory)\n",
    "\n",
    "    messages = [HumanMessage(content=\"Whats the weather in SF?\")]\n",
    "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v)\n",
    "    \n",
    "    print(abot.graph.get_state(thread))\n",
    "    print(abot.graph.get_state(thread).next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code below allows us to allow the Human to interrupt before calling a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8939c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17014876",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"Whats the weather in LA?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)\n",
    "while abot.graph.get_state(thread).next:\n",
    "    print(\"\\n\", abot.graph.get_state(thread),\"\\n\")\n",
    "    _input = input(\"proceed?\")\n",
    "    if _input != \"y\":\n",
    "        print(\"aborting\")\n",
    "        break\n",
    "    for event in abot.graph.stream(None, thread):\n",
    "        for v in event.values():\n",
    "            print(v)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1733ab7d",
   "metadata": {},
   "source": [
    "# State Memory\n",
    "\n",
    "- a snapshot it stored for each state: `AgentState`, `thread`, `thread_ts`\n",
    "\n",
    "<img src=\"thread_snapshot.png\" alt=\"Thread Snapshot\" title=\"Thread Snapshot\" width=\"400\">\n",
    "\n",
    "- `g.get_state_history(thread)` rturn siterator over all `StateSnapshots`\n",
    "- `g.invoke(None, {...,thread,thread_ts,..})`\n",
    "- `g.stream(None, {...,thread,thread_ts,..})`\n",
    "- `g.get_state({thread, thread_ts})` \n",
    "    - to modify it: `g.update_state(thread, state1m.values)` if you run stream it will use the modified state as the starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"Whats the weather in LA?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)\n",
    "current_values = abot.graph.get_state(thread)\n",
    "current_values.values['messages'][-1]\n",
    "current_values.values['messages'][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c98d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = current_values.values['messages'][-1].tool_calls[0]['id']\n",
    "current_values.values['messages'][-1].tool_calls = [\n",
    "    {'name': 'tavily_search_results_json',\n",
    "  'args': {'query': 'current weather in Louisiana'},\n",
    "  'id': _id}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17faebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.update_state(thread, current_values.values)\n",
    "abot.graph.get_state(thread)\n",
    "for event in abot.graph.stream(None, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time Travel\n",
    "states = []\n",
    "for state in abot.graph.get_state_history(thread):\n",
    "    print(state)\n",
    "    print('--')\n",
    "    states.append(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba7bbd9",
   "metadata": {},
   "source": [
    "To fetch the same state as was filmed, the offset below is changed to `-3` from `-1`. This accounts for the initial state `__start__` and the first state that are now stored to state memory with the latest version of software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71597e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay = states[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ba3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046267a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, to_replay.config):\n",
    "    for k, v in event.items():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64272e84",
   "metadata": {},
   "source": [
    "# Go back in time and edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319241fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb183fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay.values['messages'][-1].tool_calls[0]['id']\n",
    "to_replay.values['messages'][-1].tool_calls = [{'name': 'tavily_search_results_json',\n",
    "  'args': {'query': 'current weather in LA, accuweather'},\n",
    "  'id': _id}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d3c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_state = abot.graph.update_state(to_replay.config, to_replay.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, branch_state):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355fcd73",
   "metadata": {},
   "source": [
    "# Add Message to a state at a given time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24336fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45717fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay.values['messages'][-1].tool_calls[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_update = {\"messages\": [ToolMessage(\n",
    "    tool_call_id=_id,\n",
    "    name=\"tavily_search_results_json\",\n",
    "    content=\"54 degree celcius\",\n",
    ")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_and_add = abot.graph.update_state(\n",
    "    to_replay.config, \n",
    "    state_update, \n",
    "    as_node=\"action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7fdeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, branch_and_add):\n",
    "    for k, v in event.items():\n",
    "        print(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
