{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5db4e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed9ae7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openai.OpenAI object at 0x1192bbdd0>\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57dbe052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wesley: This is a chat completion object.\n",
      "ChatCompletion(id='chatcmpl-BqRFopdqWVzX9t6q92supiq69sTkp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1751837520, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=9, total_tokens=18, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world\"}]\n",
    ")\n",
    "print(\"Wesley: This is a chat completion object.\")\n",
    "print(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909212b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wesley: Within this object, there contains the context of the response to the message/query the user passed in.\n",
      "Hello there! How may I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(\"Wesley: Within this object, there contains the context of the response to the message/query the user passed in.\")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150aee5",
   "metadata": {},
   "source": [
    "# Building an Agent from Stratch\n",
    "Paper Link: https://react-lm.github.io\n",
    "\n",
    "GitHub: https://github.com/ysymyth/ReAct\n",
    "\n",
    "![react_framework](react_framework.png \"ReAct Framework\")\n",
    "\n",
    "Reason Only or Chain-of-thought was an LLM's ability to reason and trace their own though. WebGPT allowed the LLM to verify factual accuracy of a language model through web browsing. The ReAct framework (Reason + Act) combines both chain-of-thought prompting with acting (e.g. WebGPT) to outperform the current benchmarks. \n",
    "\n",
    "A ReAct prompt sonsists of few-shot task-solving trajectories with human written text reasoning traces and actions, as well as environment observations in response to actions. The baseline (i.e. chain-of-thought) suffers from misinformation as it is not grounded to external environment (i.e. the internet) to obtain and update information and relies on internally trained data. Act-only baseline suffers from lack of reasoning, unable to synthesize the final answer.\n",
    "\n",
    "![react_example](react_example.png \"ReAct Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a79ccee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    " \n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4o\", \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b98e7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "average_dog_weight:\n",
    "e.g. average_dog_weight: Collie\n",
    "returns average weight of a dog when given the breed\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: How much does a Bulldog weigh?\n",
    "Thought: I should look the dogs weight using average_dog_weight\n",
    "Action: average_dog_weight: Bulldog\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: A Bulldog weights 51 lbs\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: A bulldog weights 51 lbs\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(what):\n",
    "    return eval(what) # evaluates a string\n",
    "\n",
    "def average_dog_weight(name):\n",
    "    if name in \"Scottish Terrier\": \n",
    "        return(\"Scottish Terriers average 20 lbs\")\n",
    "    elif name in \"Border Collie\":\n",
    "        return(\"a Border Collies average weight is 37 lbs\")\n",
    "    elif name in \"Toy Poodle\":\n",
    "        return(\"a toy poodles average weight is 7 lbs\")\n",
    "    else:\n",
    "        return(\"An average dog weights 50 lbs\")\n",
    "\n",
    "## the keys are just strings (action name that the LLM says)\n",
    "## the values are the actual python function objects (not just names), but the function reference\n",
    "\n",
    "## this known_actions[\"calculate\"] is the function calculate\n",
    "known_actions = {\n",
    "    \"calculate\": calculate,\n",
    "    \"average_dog_weight\": average_dog_weight\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c14457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Agent object at 0x119221d90>\n"
     ]
    }
   ],
   "source": [
    "abot = Agent(prompt)\n",
    "print(abot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e282919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should look up the average weight of a Toy Poodle using the average_dog_weight action.\n",
      "Action: average_dog_weight: Toy Poodle\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = abot(\"How much does a toy poodle weigh?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ad6b0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a toy poodles average weight is 7 lbs'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = average_dog_weight(\"Toy Poodle\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "332d10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff57115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: A Toy Poodle weighs an average of 7 lbs.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd88aaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\naverage_dog_weight:\\ne.g. average_dog_weight: Collie\\nreturns average weight of a dog when given the breed\\n\\nExample session:\\n\\nQuestion: How much does a Bulldog weigh?\\nThought: I should look the dogs weight using average_dog_weight\\nAction: average_dog_weight: Bulldog\\nPAUSE\\n\\nYou will be called again with this:\\n\\nObservation: A Bulldog weights 51 lbs\\n\\nYou then output:\\n\\nAnswer: A bulldog weights 51 lbs'},\n",
       " {'role': 'user', 'content': 'How much does a toy poodle weigh?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: I should look up the average weight of a Toy Poodle using the average_dog_weight action.\\nAction: average_dog_weight: Toy Poodle\\nPAUSE'},\n",
       " {'role': 'user',\n",
       "  'content': 'Observation: a toy poodles average weight is 7 lbs'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Answer: A Toy Poodle weighs an average of 7 lbs.'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17124199",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1d4022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thought: I need to find the average weight of both a Border Collie and a Scottish Terrier, then add them together to get the combined weight.\\nAction: average_dog_weight: Border Collie\\nPAUSE'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "abot(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd93e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: a Border Collies average weight is 37 lbs\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Border Collie\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69332531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action: average_dog_weight: Scottish Terrier\\nPAUSE'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e45e6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: Scottish Terriers average 20 lbs\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(average_dog_weight(\"Scottish Terrier\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59628a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thought: Now that I have the average weights of both the Border Collie and the Scottish Terrier, I can calculate their combined weight.\\nAction: calculate: 37 + 20\\nPAUSE'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7240e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 57\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(eval(\"37 + 20\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74d79c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: The combined weight of a Border Collie and a Scottish Terrier is 57 lbs.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b5ce6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\naverage_dog_weight:\\ne.g. average_dog_weight: Collie\\nreturns average weight of a dog when given the breed\\n\\nExample session:\\n\\nQuestion: How much does a Bulldog weigh?\\nThought: I should look the dogs weight using average_dog_weight\\nAction: average_dog_weight: Bulldog\\nPAUSE\\n\\nYou will be called again with this:\\n\\nObservation: A Bulldog weights 51 lbs\\n\\nYou then output:\\n\\nAnswer: A bulldog weights 51 lbs'},\n",
       " {'role': 'user',\n",
       "  'content': 'I have 2 dogs, a border collie and a scottish terrier. What is their combined weight'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: I need to find the average weight of both a Border Collie and a Scottish Terrier, then add them together to get the combined weight.\\nAction: average_dog_weight: Border Collie\\nPAUSE'},\n",
       " {'role': 'user',\n",
       "  'content': 'Observation: a Border Collies average weight is 37 lbs'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Action: average_dog_weight: Scottish Terrier\\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: Scottish Terriers average 20 lbs'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: Now that I have the average weights of both the Border Collie and the Scottish Terrier, I can calculate their combined weight.\\nAction: calculate: 37 + 20\\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: 57'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Answer: The combined weight of a Border Collie and a Scottish Terrier is 57 lbs.'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2e290",
   "metadata": {},
   "source": [
    "# Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_re = re.compile('^Action: (\\w+): (.*)$')   # python regular expression to selection action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d09e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns: \n",
    "        i+=1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [\n",
    "            action_re.match(a) \n",
    "            for a in result.split('\\n') \n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        if actions:\n",
    "            # if there is an action to run\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
    "            print(\" -- running {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b69830b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the average weight of both a Border Collie and a Scottish Terrier, then add them together to find the combined weight.\n",
      "Action: average_dog_weight: Border Collie\n",
      "PAUSE\n",
      " -- running average_dog_weight Border Collie\n",
      "Observation: a Border Collies average weight is 37 lbs\n",
      "Action: average_dog_weight: Scottish Terrier\n",
      "PAUSE\n",
      " -- running average_dog_weight Scottish Terrier\n",
      "Observation: Scottish Terriers average 20 lbs\n",
      "Thought: Now that I have the average weights of both dogs, I can calculate their combined weight by adding the two values together.\n",
      "Action: calculate: 37 + 20\n",
      "PAUSE\n",
      " -- running calculate 37 + 20\n",
      "Observation: 57\n",
      "Answer: The combined average weight of a Border Collie and a Scottish Terrier is 57 lbs.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bdb98d",
   "metadata": {},
   "source": [
    "I register my functions within a python dictionary\n",
    "\n",
    "``` python \n",
    "known_actions = {\n",
    "    \"calculate\": calculate,\n",
    "    \"average_dog_weight\": average_dog_weight\n",
    "}\n",
    "```\n",
    "\n",
    "where:\n",
    "- keys are just strings (action name that LLM says)\n",
    "- values are the actual python function objects (not their name but the function references)\n",
    "\n",
    "So `known_actions[\"calculate\"]` is the function `calculate`.\n",
    "\n",
    "Within my `query` loop, the LLM returns something like:\n",
    "```\n",
    "Action: calculate: 4 * 7 / 3\n",
    "```\n",
    "The code use a **regex** or **regular expression** to parse that string\n",
    "\n",
    "```python\n",
    "action, action_input = actions[0].groups()\n",
    "```\n",
    "\n",
    "The function call is done:\n",
    "```python\n",
    "observation = known_actions[action](action_input)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60224da9",
   "metadata": {},
   "source": [
    "# Building AI Agents using LangGraph\n",
    "\n",
    "\n",
    "<img src=\"langchain_prompts.png\" alt=\"LangChain Prompts\" title=\"LangChain Tools\" width=\"400\">\n",
    "\n",
    "Prompts are reuseable from the Hub\n",
    "\n",
    "<img src=\"langchain_tools.png\" alt=\"LangChain Tools\" title=\"LangChain Tools\" width=\"400\">\n",
    "\n",
    "The most code that needs to be written are loops. LangGraph helps describe the control flow of an AI system. You can create cyclic graphs, allow persistence, and Human-in-the-loop features. \n",
    "\n",
    "\n",
    "<img src=\"agents_from_paper_architecture.png\" alt=\"Graphs\" title=\"Graphs\" width=\"400\">\n",
    "\n",
    "- LangGraph is an extension of LangChain that support graph that support single and multi agent flows that are represented as graphs \n",
    "Terminology\n",
    "- Nodes: agents or functions \n",
    "- Edges: connect nodes\n",
    "- Conditional Edges: decision about which node to go to next\n",
    "\n",
    "<img src=\"agent_state.png\" alt=\"Agent State\" title=\"Agent State\" width=\"400\">\n",
    "\n",
    "- Agent State is accessible to all parts of the graph and is local to the graph\n",
    "- Can be stored in persistents layer such that it can be accessed at any time\n",
    "- Agent State stores: `chat_history`, `agent_outcome`, `intermediate_steps`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ccb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91ab2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END ##loading in the states\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892d906",
   "metadata": {},
   "source": [
    "## LangChain Tools\n",
    "Link: https://python.langchain.com/api_reference/community/tools.html\n",
    "\n",
    "There are a bunch of tools accessible from LangChain that can be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "926b5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=4) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Annotated List of message from the Agent\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "683dd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c704526",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")  #reduce inference cost\n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "# ^ the tool used is what is below\n",
    "#tool = TavilySearchResults(max_results=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b6c2898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0659e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_h8x8ahfsqENfRIlZuudr1w2j', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d2f38f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in sf?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_h8x8ahfsqENfRIlZuudr1w2j', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 153, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BqjP06jzQUZwbeleGIKRaUBpywoMf', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c0d35e91-fb50-4152-8f54-df00aa7f144b-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_h8x8ahfsqENfRIlZuudr1w2j', 'type': 'tool_call'}], usage_metadata={'input_tokens': 153, 'output_tokens': 21, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"[{'title': 'San Francisco weather in July 2025 | Weather25.com', 'url': 'https://www.weather25.com/north-america/usa/california/san-francisco?page=month&month=July', 'content': 'weather25.com\\\\nSearch\\\\nweather in United States\\\\nRemove from your favorite locations\\\\nAdd to my locations\\\\nShare\\\\nweather in United States\\\\n\\\\n# San Francisco weather in July 2025\\\\n\\\\nThe temperatures in San Francisco in July are comfortable with low of 14C and and high up to 25C.\\\\n\\\\nThere is little to no rain in San Francisco during July, so its a lot easier to explore the city. Just remember to dress in warm layers, as it can still get pretty chilly. [...] Our weather forecast can give you a great sense of what weather to expect in San Francisco in July 2025.\\\\n\\\\nIf youre planning to visit San Francisco in the near future, we highly recommend that you review the 14 day weather forecast for San Francisco before you arrive.\\\\n\\\\nTemperatures\\\\nRainy Days\\\\nSnowy Days\\\\nDry Days\\\\nRainfall\\\\n11.9 [...] | Sun | Mon | Tue | Wed | Thu | Fri | Sat |\\\\n| --- | --- | --- | --- | --- | --- | --- |\\\\n|  |  | 1 Cloudy 21 /12 | 2 Partly cloudy 21 /13 | 3 Partly cloudy 21 /12 | 4 Sunny 21 /13 | 5 Sunny 21 /14 |\\\\n| 6 Sunny 20 /13 | 7 Mist 20 /12 | 8 Sunny 21 /12 | 9 Partly cloudy 21 /13 | 10 Sunny 22 /14 | 11 Sunny 23 /14 | 12 Sunny 22 /14 |', 'score': 0.9615375}, {'title': 'Weather in San Francisco in July 2025 - Detailed Forecast', 'url': 'https://www.easeweather.com/north-america/united-states/california/city-and-county-of-san-francisco/san-francisco/july', 'content': 'easeweather.com\\\\nUnited States weather\\\\n\\\\n# Weather in San Francisco for July 2025\\\\n\\\\n### Temperatures\\\\n\\\\nIn general, the average temperature in San Francisco at the beginning of July is 20.9 F. As the month progressed, temperatures tended to slightly decrease, reaching an average of 20.6 F by the end of July.\\\\n\\\\n### Rain \\\\n\\\\nPrecipitation in San Francisco during July is a rare event, with an average of fewer than 2 rainy days.\\\\n\\\\n### More\\\\n\\\\nNew! Chat with our AI weatherman - its amazing and free.', 'score': 0.9477354}]\", name='tavily_search_results_json', tool_call_id='call_h8x8ahfsqENfRIlZuudr1w2j'),\n",
       "  AIMessage(content=\"The weather in San Francisco in July is comfortable with temperatures ranging from a low of 14C to a high of 25C. There is little to no rain during July in San Francisco, making it easier to explore the city. If you are planning to visit San Francisco in the near future, it's recommended to review the 14-day weather forecast before you arrive.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 809, 'total_tokens': 885, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BqjP1RdazJBzw776qtPvUYHGbICBk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c0c4017d-2d45-46bd-826c-9437e27a9b1f-0', usage_metadata={'input_tokens': 809, 'output_tokens': 76, 'total_tokens': 885, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80c1f8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The weather in San Francisco in July is comfortable with temperatures ranging from a low of 14C to a high of 25C. There is little to no rain during July in San Francisco, making it easier to explore the city. If you are planning to visit San Francisco in the near future, it's recommended to review the 14-day weather forecast before you arrive.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c328929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_P2Z1Q7itKCDIyU7jFvMqxMoe', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_Vamzyoypaijg1hrposX9SndO', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF and LA?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a88e336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': '2024 Super Bowl winner'}, 'id': 'call_vE6Xzd9Cr1ku3Nl2WvLazHjb', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Kansas City Chiefs headquarters location'}, 'id': 'call_WSTqTP2b4rzIflvNXfNRXG7N', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'GDP of Missouri 2024'}, 'id': 'call_q9HgO83p9tqACGyS0vG79OvF', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "result['messages'][-1].content\n",
    "result['messages'][-1].content\n",
    "# Note, the query was modified to produce more consistent results. \n",
    "# Results may vary per run and over time as search information and models change.\n",
    "\n",
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "model = ChatOpenAI(model=\"gpt-4o\")  # requires more advanced model\n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56ee4640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Super Bowl in 2024 was won by the Kansas City Chiefs.\n",
      "\n",
      "2. The headquarters of the Kansas City Chiefs is located in Kansas City, Missouri.\n",
      "\n",
      "3. The GDP of Missouri in 2024 was approximately $461 billion.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e5ec4",
   "metadata": {},
   "source": [
    "# Agentic Search Tool\n",
    "\n",
    "<img src=\"agentic_search.png\" alt=\"Agentic Search\" title=\"Agentic Search\" width=\"400\">\n",
    "\n",
    "An agent can use search tool in order to be make better responses given accurate information from searching (similar to WebGPT)\n",
    "\n",
    "<img src=\"searchtool_impl.png\" alt=\"Agentic Search\" title=\"Agentic Search\" width=\"400\">\n",
    "Under the hood, when a user passes in a query, the agent can use sub-queries (i.e. chain-of-thought) to break down the tasks into sub-tasks. Then, each task that the agent layed out can be searched for using RAG from online sources. Using these sources, the agent will accuracy score and filter the sources to find the best K returns. \n",
    "\n",
    "# Persistence and Streaming\n",
    "- Persistence allows you to maintain your AgentState at a given time and allows you to access this information\n",
    "- Streaming you can emit signals of what's going on during that moment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e42f2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51b3659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an in memory database\n",
    "# when you refresh the notebook this should disappear\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35c7df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61000dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0afe9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add streaming\n",
    "message = [HumanMessage(content=\"what is the weather in sf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f4c8285",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ddf427e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_GeneratorContextManager' object has no attribute 'get_next_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m abot\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages}, thread):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_hw4/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2466\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_during \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2465\u001b[0m     config[CONF][CONFIG_KEY_CHECKPOINT_DURING] \u001b[38;5;241m=\u001b[39m checkpoint_during\n\u001b[0;32m-> 2466\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SyncPregelLoop(\n\u001b[1;32m   2467\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2468\u001b[0m     stream\u001b[38;5;241m=\u001b[39mStreamProtocol(stream\u001b[38;5;241m.\u001b[39mput, stream_modes),\n\u001b[1;32m   2469\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m   2470\u001b[0m     store\u001b[38;5;241m=\u001b[39mstore,\n\u001b[1;32m   2471\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   2472\u001b[0m     checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer,\n\u001b[1;32m   2473\u001b[0m     nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes,\n\u001b[1;32m   2474\u001b[0m     specs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[1;32m   2475\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2476\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   2477\u001b[0m     stream_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_asis,\n\u001b[1;32m   2478\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   2479\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   2480\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   2481\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during\n\u001b[1;32m   2482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m checkpoint_during \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m config[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_CHECKPOINT_DURING, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   2484\u001b[0m     trigger_to_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_to_nodes,\n\u001b[1;32m   2485\u001b[0m     migrate_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_migrate_checkpoint,\n\u001b[1;32m   2486\u001b[0m     retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2487\u001b[0m     cache_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_policy,\n\u001b[1;32m   2488\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[1;32m   2489\u001b[0m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[1;32m   2490\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PregelRunner(\n\u001b[1;32m   2491\u001b[0m         submit\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   2492\u001b[0m             CONFIG_KEY_RUNNER_SUBMIT, weakref\u001b[38;5;241m.\u001b[39mWeakMethod(loop\u001b[38;5;241m.\u001b[39msubmit)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2495\u001b[0m         node_finished\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_NODE_FINISHED),\n\u001b[1;32m   2496\u001b[0m     )\n\u001b[1;32m   2497\u001b[0m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_hw4/lib/python3.11/site-packages/langgraph/pregel/loop.py:930\u001b[0m, in \u001b[0;36mSyncPregelLoop.__init__\u001b[0;34m(self, input, stream, config, store, cache, checkpointer, nodes, specs, trigger_to_nodes, manager, interrupt_after, interrupt_before, input_keys, output_keys, stream_keys, migrate_checkpoint, retry_policy, cache_policy, checkpoint_during)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack \u001b[38;5;241m=\u001b[39m ExitStack()\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpointer:\n\u001b[0;32m--> 930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer_get_next_version \u001b[38;5;241m=\u001b[39m checkpointer\u001b[38;5;241m.\u001b[39mget_next_version\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer_put_writes \u001b[38;5;241m=\u001b[39m checkpointer\u001b[38;5;241m.\u001b[39mput_writes\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer_put_writes_accepts_task_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    933\u001b[0m         signature(checkpointer\u001b[38;5;241m.\u001b[39mput_writes)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_path\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_GeneratorContextManager' object has no attribute 'get_next_version'"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92d12877",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_GeneratorContextManager' object has no attribute 'get_next_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m messages \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat about in la?\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      2\u001b[0m thread \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m abot\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages}, thread):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(v)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_hw4/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2466\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_during \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2465\u001b[0m     config[CONF][CONFIG_KEY_CHECKPOINT_DURING] \u001b[38;5;241m=\u001b[39m checkpoint_during\n\u001b[0;32m-> 2466\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SyncPregelLoop(\n\u001b[1;32m   2467\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2468\u001b[0m     stream\u001b[38;5;241m=\u001b[39mStreamProtocol(stream\u001b[38;5;241m.\u001b[39mput, stream_modes),\n\u001b[1;32m   2469\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m   2470\u001b[0m     store\u001b[38;5;241m=\u001b[39mstore,\n\u001b[1;32m   2471\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   2472\u001b[0m     checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer,\n\u001b[1;32m   2473\u001b[0m     nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes,\n\u001b[1;32m   2474\u001b[0m     specs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[1;32m   2475\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2476\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   2477\u001b[0m     stream_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_asis,\n\u001b[1;32m   2478\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   2479\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   2480\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   2481\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during\n\u001b[1;32m   2482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m checkpoint_during \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m config[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_CHECKPOINT_DURING, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   2484\u001b[0m     trigger_to_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_to_nodes,\n\u001b[1;32m   2485\u001b[0m     migrate_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_migrate_checkpoint,\n\u001b[1;32m   2486\u001b[0m     retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2487\u001b[0m     cache_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_policy,\n\u001b[1;32m   2488\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[1;32m   2489\u001b[0m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[1;32m   2490\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PregelRunner(\n\u001b[1;32m   2491\u001b[0m         submit\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   2492\u001b[0m             CONFIG_KEY_RUNNER_SUBMIT, weakref\u001b[38;5;241m.\u001b[39mWeakMethod(loop\u001b[38;5;241m.\u001b[39msubmit)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2495\u001b[0m         node_finished\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_NODE_FINISHED),\n\u001b[1;32m   2496\u001b[0m     )\n\u001b[1;32m   2497\u001b[0m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_hw4/lib/python3.11/site-packages/langgraph/pregel/loop.py:930\u001b[0m, in \u001b[0;36mSyncPregelLoop.__init__\u001b[0;34m(self, input, stream, config, store, cache, checkpointer, nodes, specs, trigger_to_nodes, manager, interrupt_after, interrupt_before, input_keys, output_keys, stream_keys, migrate_checkpoint, retry_policy, cache_policy, checkpoint_during)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack \u001b[38;5;241m=\u001b[39m ExitStack()\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpointer:\n\u001b[0;32m--> 930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer_get_next_version \u001b[38;5;241m=\u001b[39m checkpointer\u001b[38;5;241m.\u001b[39mget_next_version\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer_put_writes \u001b[38;5;241m=\u001b[39m checkpointer\u001b[38;5;241m.\u001b[39mput_writes\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer_put_writes_accepts_task_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    933\u001b[0m         signature(checkpointer\u001b[38;5;241m.\u001b[39mput_writes)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_path\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_GeneratorContextManager' object has no attribute 'get_next_version'"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f307df",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70e51b",
   "metadata": {},
   "source": [
    "# Humans in the Loop\n",
    "\n",
    "go to the human_intervention_langchain_ai_agent.ipynb\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
